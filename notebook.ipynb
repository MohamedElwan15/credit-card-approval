{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35aebf2e-0635-4fef-bc9a-877b6a20fb13",
   "metadata": {},
   "source": [
    "![Credit card being held in hand](credit_card.jpg)\n",
    "\n",
    "Commercial banks receive _a lot_ of applications for credit cards. Many of them get rejected for many reasons, like high loan balances, low income levels, or too many inquiries on an individual's credit report, for example. Manually analyzing these applications is mundane, error-prone, and time-consuming (and time is money!). Luckily, this task can be automated with the power of machine learning and pretty much every commercial bank does so nowadays. In this workbook, you will build an automatic credit card approval predictor using machine learning techniques, just like real banks do.\n",
    "\n",
    "### The Data\n",
    "\n",
    "The data is a small subset of the Credit Card Approval dataset from the UCI Machine Learning Repository showing the credit card applications a bank receives. This dataset has been loaded as a `pandas` DataFrame called `cc_apps`. The last column in the dataset is the target value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e86b1e8-a3fa-4b09-982f-795f218bd1a6",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 30,
    "lastExecutedAt": 1757789121069,
    "lastExecutedByKernel": "e75fc8c8-30c1-484c-b807-8e4afdd7ac1c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.impute import SimpleImputer\n\n# Load the dataset\ncc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \nprint(cc_apps.head())\nprint(cc_apps.shape)",
    "outputsMetadata": {
     "0": {
      "height": 164,
      "type": "stream"
     }
    },
    "version": "ag-charts-v1",
    "visualizeDataframe": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load the dataset\n",
    "cc_apps = pd.read_csv(\"cc_approvals.data\", header=None) \n",
    "print(cc_apps.head())\n",
    "print(cc_apps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdb9175-87c4-46e4-9cb2-0229723f7915",
   "metadata": {},
   "source": [
    "We'll start by cleaning the data, scaling and dealing with missing values first.\n",
    "## 1. Data Cleaning\n",
    "###    **1.1 Dealing with missing Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874d384f-89e8-4f0b-9917-56cdd13be81e",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 81,
    "lastExecutedAt": 1757789121150,
    "lastExecutedByKernel": "e75fc8c8-30c1-484c-b807-8e4afdd7ac1c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Check raw unique values per column\nfor col in cc_apps.columns:\n    if \"?\" in cc_apps[col].unique():\n        print(f\"Column {col} has '?'\")\ncc_apps = cc_apps.replace('?', np.nan) #as in UCI missing values are labeled as '?' which function won't identify as NaN\nprint(cc_apps.isna().sum().sort_values()) \nimputer = SimpleImputer(strategy='most_frequent')\ncc_apps = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\nprint(cc_apps.isna().sum().sort_values()) ",
    "outputsMetadata": {
     "0": {
      "height": 269,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 0 has '?'\n",
      "Column 1 has '?'\n",
      "Column 3 has '?'\n",
      "Column 4 has '?'\n",
      "Column 5 has '?'\n",
      "Column 6 has '?'\n",
      "2      0\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "10     0\n",
      "11     0\n",
      "12     0\n",
      "13     0\n",
      "3      6\n",
      "4      6\n",
      "5      9\n",
      "6      9\n",
      "0     12\n",
      "1     12\n",
      "dtype: int64\n",
      "2          0\n",
      "1_42.50    0\n",
      "1_42.25    0\n",
      "1_42.17    0\n",
      "1_42.08    0\n",
      "          ..\n",
      "1_27.25    0\n",
      "1_27.17    0\n",
      "1_27.00    0\n",
      "1_28.00    0\n",
      "11_s       0\n",
      "Length: 382, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check raw unique values per column\n",
    "for col in cc_apps.columns:\n",
    "    if \"?\" in cc_apps[col].unique():\n",
    "        print(f\"Column {col} has '?'\")\n",
    "cc_apps = cc_apps.replace('?', np.nan) #as in UCI missing values are labeled as '?' which function won't identify as NaN\n",
    "print(cc_apps.isna().sum().sort_values()) \n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "cc_apps = pd.DataFrame(imputer.fit_transform(cc_apps), columns=cc_apps.columns)\n",
    "print(cc_apps.isna().sum().sort_values()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7646762-5873-4873-b69d-09f96a897f7a",
   "metadata": {},
   "source": [
    "As seen the data has no ? or NaN so it has no missing values so there is no need to deal with it.\n",
    "### **1.2 Encoding categorical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9987aa-fdeb-40d0-887f-db103fcc6553",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 97,
    "lastExecutedAt": 1757789121247,
    "lastExecutedByKernel": "e75fc8c8-30c1-484c-b807-8e4afdd7ac1c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "cat_cols = cc_apps.select_dtypes(include=['object']).columns\ncc_apps = pd.get_dummies(cc_apps, columns=cat_cols, drop_first=True)\nprint(cc_apps)",
    "outputsMetadata": {
     "0": {
      "height": 311,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          2     7   10     12  0_b  1_15.17  ...  6_v  6_z  8_t  9_t  11_p  11_s\n",
      "0     0.000  1.25  1.0    0.0  1.0      0.0  ...  1.0  0.0  1.0  1.0   0.0   0.0\n",
      "1     4.460  3.04  6.0  560.0  0.0      0.0  ...  0.0  0.0  1.0  1.0   0.0   0.0\n",
      "2     0.500  1.50  0.0  824.0  0.0      0.0  ...  0.0  0.0  1.0  0.0   0.0   0.0\n",
      "3     1.540  3.75  5.0    3.0  1.0      0.0  ...  1.0  0.0  1.0  1.0   0.0   0.0\n",
      "4     5.625  1.71  0.0    0.0  1.0      0.0  ...  1.0  0.0  1.0  0.0   0.0   1.0\n",
      "..      ...   ...  ...    ...  ...      ...  ...  ...  ...  ...  ...   ...   ...\n",
      "685  10.085  1.25  0.0    0.0  1.0      0.0  ...  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "686   0.750  2.00  2.0  394.0  0.0      0.0  ...  1.0  0.0  0.0  1.0   0.0   0.0\n",
      "687  13.500  2.00  1.0    1.0  0.0      0.0  ...  0.0  0.0  0.0  1.0   0.0   0.0\n",
      "688   0.205  0.04  0.0  750.0  1.0      0.0  ...  1.0  0.0  0.0  0.0   0.0   0.0\n",
      "689   3.375  8.29  0.0    0.0  1.0      0.0  ...  0.0  0.0  0.0  0.0   0.0   0.0\n",
      "\n",
      "[690 rows x 382 columns]\n"
     ]
    }
   ],
   "source": [
    "cat_cols = cc_apps.select_dtypes(include=['object']).columns\n",
    "cc_apps = pd.get_dummies(cc_apps, columns=cat_cols, drop_first=True)\n",
    "print(cc_apps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0c4c79-4517-4292-9e77-7ababa544016",
   "metadata": {},
   "source": [
    "### **1.3 Spliting the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d8bc2a-df7d-4830-bead-c4b05115b3a2",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 55,
    "lastExecutedAt": 1757789121302,
    "lastExecutedByKernel": "e75fc8c8-30c1-484c-b807-8e4afdd7ac1c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "cc_apps.columns = cc_apps.columns.astype(str)\nX = cc_apps.iloc[:,:-1]\ny = cc_apps.iloc[:,-1]\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42, stratify = y)"
   },
   "outputs": [],
   "source": [
    "cc_apps.columns = cc_apps.columns.astype(str)\n",
    "X = cc_apps.iloc[:,:-1]\n",
    "y = cc_apps.iloc[:,-1].map({'+': 1, '-': 0})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e7dc26-7b45-4849-bf9a-d2af0b26e9c3",
   "metadata": {},
   "source": [
    "### **1.4 Data Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8824a83-10f4-4d23-a2b6-57de9f18ab2b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 54,
    "lastExecutedAt": 1757789121358,
    "lastExecutedByKernel": "e75fc8c8-30c1-484c-b807-8e4afdd7ac1c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd9c5f-7a32-4d4f-b5f4-7ca2bec5a133",
   "metadata": {},
   "source": [
    "## **2. The prediction model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458c3b9-e8d7-4734-8588-43bc3ee18831",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 37468,
    "lastExecutedAt": 1757789158826,
    "lastExecutedByKernel": "e75fc8c8-30c1-484c-b807-8e4afdd7ac1c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "param_grid = {'C': np.logspace(-4,4,20), \"solver\": ['liblinear','lbfgs']}\nlog_reg = LogisticRegression()\ngrid_search = GridSearchCV(log_reg, param_grid, cv = 5, scoring = 'accuracy')\ngrid_search.fit(X_train_scaled, y_train)"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;lbfgs&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-29\" type=\"checkbox\" ><label for=\"sk-estimator-id-29\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-30\" type=\"checkbox\" ><label for=\"sk-estimator-id-30\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                         'solver': ['liblinear', 'lbfgs']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'C': np.logspace(-4,4,20), \"solver\": ['liblinear','lbfgs']}\n",
    "log_reg = LogisticRegression()\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv = 5, scoring = 'accuracy')\n",
    "grid_search.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06496935-d1a4-48b7-bb70-8ccefc620b7b",
   "metadata": {},
   "source": [
    "## 3. Test Model Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c659c-5f36-4281-b268-8ec30a288bc1",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 150,
    "lastExecutedAt": 1757789158977,
    "lastExecutedByKernel": "e75fc8c8-30c1-484c-b807-8e4afdd7ac1c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "print(\"Best Parameters: \", grid_search.best_params_)\nprint(\"Best Score: \", grid_search.best_score_)\nbest_model = grid_search.best_estimator_\nbest_score = best_model.score(X_test_scaled, y_test)\nprint(\"Test Accuracy:\", best_score)",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'C': 0.0001, 'solver': 'lbfgs'}\n",
      "Best Score:  0.9171821305841924\n",
      "Test Accuracy: 0.9178743961352657\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Parameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)\n",
    "best_model = grid_search.best_estimator_\n",
    "best_score = best_model.score(X_test_scaled, y_test)\n",
    "print(\"Test Accuracy:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4732f37-fb5f-464a-8d0a-3d973306c6b5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11,
    "lastExecutedAt": 1757789158988,
    "lastExecutedByKernel": "e75fc8c8-30c1-484c-b807-8e4afdd7ac1c",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": ""
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
